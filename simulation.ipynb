{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import statsmodels.api as sm\n",
    "from IPython.core.display import HTML, Image\n",
    "import shlex\n",
    "import copy\n",
    "from scipy.stats    import norm\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import\n",
    "\n",
    "- More or less I used your code for the import process. \n",
    "\n",
    "\n",
    "- I added a mean value for each error variable that can be defined in the init file such that you are able to play around with it and not only with the standard deviation and the correlations. (I am not sure if this is necessary? Maybe not as useful as I thought in the first moment)\n",
    "\n",
    "\n",
    "- Furthermore I integrated elements into the 'DIST' key of the imported dictionary that contain all mean, sd and corrcoef s.t. I can use them in the simulation function to simplify the definition process. I am aware of the fact that the loops are messy, maybe it is also not as good as I thought before implementing them.\n",
    "\n",
    "\n",
    "- Finally I added an element that defines the distribution of the eroor terms ('DIST' 'type')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def import_process(file_):\n",
    "    '''reads the initialization file and provides an dictionary with parameters for the simulation'''\n",
    "    dict_={}\n",
    "    for line in open(file_).readlines():\n",
    "        \n",
    "        list_=shlex.split(line)\n",
    "        \n",
    "        \n",
    "        is_empty = (list_ == [])\n",
    "        \n",
    "        if not is_empty:\n",
    "            is_keyword = list_[0].isupper()\n",
    "        else:\n",
    "            is_keyword = False\n",
    "\n",
    "\n",
    "        if is_empty:\n",
    "            continue\n",
    "            \n",
    "        if is_keyword:\n",
    "            keyword= list_[0]\n",
    "            dict_[keyword]={}\n",
    "            continue\n",
    "        \n",
    "        if keyword not in ['BENE']:\n",
    "            _process_not_bene(list_, dict_, keyword)\n",
    "            \n",
    "        else:\n",
    "            _process_in_bene(list_, dict_, keyword)\n",
    "        \n",
    "    del dict_['BENE']\n",
    "    \n",
    "    # Add auxiliary objects\n",
    "    dict_ = _add_auxiliary(dict_)\n",
    "        \n",
    "    return dict_        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _process_not_bene(list_, dict_, keyword):\n",
    "        \n",
    "    name, val = list_[0], list_[1]\n",
    "\n",
    "\n",
    "    if name not in dict_[keyword].keys():\n",
    "        if name in ['coeff']:\n",
    "            dict_[keyword][name] = []\n",
    "\n",
    "    # Type conversion\n",
    "    if name in ['agents', 'maxiter']:\n",
    "        val = int(val)\n",
    "    elif name in ['source', 'algorithm', 'start', 'version', 'type']:\n",
    "        val = str(val)\n",
    "    else:\n",
    "        val = float(val)\n",
    "\n",
    "    # Collect information\n",
    "    if name in ['coeff']:\n",
    "        dict_[keyword][name] += [val]\n",
    "    else:\n",
    "        dict_[keyword][name] = val\n",
    "\n",
    "    # Finishing.\n",
    "    return dict_  \n",
    "\n",
    "def _process_in_bene(list_, dict_, keyword):\n",
    "    \"\"\" This function processes the BENE part of the initialization file.\n",
    "    \"\"\"\n",
    "    # Distribute information\n",
    "    name, val_treated, val_untreated = list_[0], list_[1], list_[2]\n",
    "\n",
    "    # Initialize dictionary\n",
    "    if 'TREATED' not in dict_.keys():\n",
    "        for subgroup in ['TREATED', 'UNTREATED']:\n",
    "            dict_[subgroup] = {}\n",
    "            dict_[subgroup]['coeff'] = []\n",
    "            dict_[subgroup]['int'] = None\n",
    "            dict_[subgroup]['sd'] = None\n",
    "            dict_[subgroup]['mean'] = None\n",
    "\n",
    "    # Type conversion\n",
    "    val_treated = float(val_treated)\n",
    "    val_untreated = float(val_untreated)\n",
    "\n",
    "    # Collect information\n",
    "    if name in ['coeff']:\n",
    "        dict_['TREATED'][name] += [val_treated]\n",
    "        dict_['UNTREATED'][name] += [val_untreated]\n",
    "    else:\n",
    "        dict_['TREATED'][name] = val_treated\n",
    "        dict_['UNTREATED'][name] = val_untreated\n",
    "\n",
    "    # Finishing\n",
    "    return dict_\n",
    "\n",
    "def _add_auxiliary(dict_):\n",
    "    \"\"\" Add some auxiliary objects.\n",
    "    \"\"\"\n",
    "    # Antibugging\n",
    "    assert (isinstance(dict_, dict))\n",
    "\n",
    "    # Initialize container\n",
    "    dict_['AUX'] = {}\n",
    "    dict_['AUX']['init_values'] = []\n",
    "\n",
    "\n",
    "    # Full set of coefficients.\n",
    "    for key_ in ['UNTREATED', 'TREATED', 'COST']:\n",
    "        dict_[key_]['all'] = [dict_[key_]['int']]\n",
    "        dict_[key_]['all'] += dict_[key_]['coeff']\n",
    "\n",
    "        dict_[key_]['all'] = np.array(dict_[key_]['all'])\n",
    "        \n",
    "    # Summarize mean and standard deviation parameters in distribution dictionary\n",
    "    \n",
    "        for j in dict_[key_].keys():\n",
    "            for i in ['mean', 'sd']:\n",
    "                if j.startswith(i):\n",
    "                    dict_['DIST'][ i + '_' + key_ ] = dict_[key_][j]\n",
    "                    \n",
    "    # Combine all mean sd and correaltion parameters in one numpy array for each category  \n",
    "    for key_ in ['all_rho', 'all_sd', 'all_mean']:\n",
    "        dict_['DIST'][key_]=[]\n",
    "\n",
    "    for key_ in sorted(dict_['DIST'].keys()):\n",
    "        if key_.startswith('rho'):\n",
    "            dict_['DIST']['all_rho'].append(dict_['DIST'][key_])\n",
    "\n",
    "        else:\n",
    "            for j in ['sd', 'mean']:\n",
    "                if key_.startswith(j):\n",
    "                    dict_['DIST']['all_' + j].append(dict_['DIST'][key_])\n",
    "    for key_ in ['all_rho', 'all_sd', 'all_mean']:\n",
    "        dict_['DIST'][key_]= np.array(dict_['DIST'][key_])\n",
    "        \n",
    "                            \n",
    "    # Delete single mean and sd parameters from 'DIST' dictionary\n",
    "    # Initiate starting values for correlation coefficients before deleting them from the 'DIST' dictionary\n",
    "    \n",
    "    for key_ in ['TREATED', 'UNTREATED', 'COST']:\n",
    "        \n",
    "        for i in list(dict_['DIST'].keys()):\n",
    "                if i.endswith(key_):\n",
    "                    del dict_['DIST'][i]\n",
    "                else:\n",
    "                    if i.startswith('rho'):\n",
    "                        dict_['AUX']['init_values'] += [dict_['DIST'][i]]\n",
    "                        del dict_['DIST'][i]\n",
    "                        \n",
    "\n",
    "    # Number of covariates\n",
    "    num_covars_out = len(dict_['TREATED']['all'])\n",
    "    num_covars_cost = len(dict_['COST']['all'])\n",
    "\n",
    "    dict_['AUX']['num_covars_out'] = num_covars_out\n",
    "    dict_['AUX']['num_covars_cost'] = num_covars_cost\n",
    "\n",
    "    # Number of parameters\n",
    "    dict_['AUX']['num_paras'] = 2 * num_covars_out + num_covars_cost + 2 + 2\n",
    "\n",
    "    # Starting values\n",
    "\n",
    "    for key_ in ['TREATED', 'UNTREATED', 'COST']:\n",
    "        dict_['AUX']['init_values'] += dict_[key_]['all'].tolist()\n",
    "\n",
    "    dict_['AUX']['init_values'] += [dict_['TREATED']['sd']]\n",
    "    dict_['AUX']['init_values'] += [dict_['TREATED']['mean']]\n",
    "\n",
    "    dict_['AUX']['init_values'] += [dict_['UNTREATED']['sd']]\n",
    "    dict_['AUX']['init_values'] += [dict_['UNTREATED']['mean']]\n",
    "\n",
    "    # Finishing\n",
    "    return dict_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation process\n",
    "\n",
    "- I splitted the simulation of the unobservables and the exogeneous variables off from the main simulation function just to equalize the simulation process. Furthermore it provides the opportunity to integrate different options for the distribution of the error terms without touching the main function\n",
    "    \n",
    "    \n",
    "- I changed the computation process of the output and the potential output variables such that it uses matrix notation. But I am not sure if it would create problems in the future. \n",
    "\n",
    "\n",
    "- I haven't inserted any test functions or assert statements yet, but I will do it as soon as possible.\n",
    "\n",
    "\n",
    "- I used your writing function for creating the output file since I am not sure how to improve it or what you want more in this regard. If there is something just tell me.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _simulate_unobservables(dist, covar, vars_, num_agents, means=None):\n",
    "    \"\"\"Creates the error term values for each type of error term variable\n",
    "    \"\"\"\n",
    "    if means is None:\n",
    "        means= np.array([0.]*len(vars_))\n",
    "\n",
    "    # Create a Covariance matrix\n",
    "    cov_ = np.diag(vars_)\n",
    "    \n",
    "    for i in range(cov_.shape[0]-1):\n",
    "        cov_[i,cov_.shape[0]-1]= covar[i]\n",
    "        cov_[cov_.shape[0]-1,i]= covar[i]\n",
    "    \n",
    "    \n",
    "    # Option to integrate case specifications for different distributions \n",
    "    \n",
    "    if dist == 'uniform':\n",
    "        pass\n",
    "    \n",
    "    elif dist == 'normal':\n",
    "        U = np.random.multivariate_normal(means,cov_, num_agents) \n",
    "    \n",
    "    else:\n",
    "        pass\n",
    "                \n",
    "    return U\n",
    "\n",
    "def _simulate_outcomes(exog, err, coeff):\n",
    "    \"\"\" Simulates the potential outcomes Y0 and Y1, the resulting\n",
    "        treatment dummy D and the realized outcome Y \"\"\"\n",
    "    \n",
    "    #Expected values for individuals\n",
    "    \n",
    "    exp_y0, exp_y1 = np.dot(coeff[0], exog[0].T), np.dot(coeff[1], exog[0].T)\n",
    "    \n",
    "    cost_exp= np.dot(coeff[2], exog[1].T)\n",
    "    \n",
    "    # Calculate expected benefit and the resulting treatment dummy\n",
    "    \n",
    "    expected_benefits = exp_y1 - exp_y0\n",
    "    \n",
    "    cost = cost_exp + err[0:,2]\n",
    "    \n",
    "    D=np.array((expected_benefits- cost > 0).astype(float))\n",
    "\n",
    "    # Realized outcome in both cases for each individual\n",
    "    \n",
    "    Y_0, Y_1 = exp_y0 + err[0:,0], exp_y0 + err[0:,1]\n",
    "    \n",
    "    # Observed outcomes\n",
    "    \n",
    "    Y = D * Y_1 + (1-D) * Y_0\n",
    "    \n",
    "    return Y, D, Y_1, Y_0 \n",
    "\n",
    "def _write_output(end, exog, source, unobserved=False):\n",
    "    \n",
    "    if not unobserved:\n",
    "        np.savetxt(source, np.column_stack((end[0],end[1], exog[0], exog[1] )), delimiter=\",\", fmt='%8.3f')\n",
    "    \n",
    "    else:\n",
    "        np.savetxt(source, np.column_stack((end[0], end[1], exog[0], exog[1], end[2], end[3])), delimiter=\",\", fmt='%8.3f')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simulation(init_dict):\n",
    "    \"\"\"Main function, defines variables by using the init_dict.\n",
    "    It creates the endogeneous variables X and Z and relies \n",
    "    on the _simulate_outcome and _simulate_unobservables functions\n",
    "    to simulate the model. Finally it writes an output file by using\n",
    "    the _write_output function.\"\"\"\n",
    "    \n",
    "    # Ensure recomputability\n",
    "    np.random.seed(123)\n",
    "    \n",
    "    # Distribute information\n",
    "    num_agents = init_dict['BASICS']['agents']\n",
    "    source = init_dict['BASICS']['source']\n",
    "\n",
    "    Y1_coeffs = init_dict['TREATED']['all']\n",
    "    Y0_coeffs = init_dict['UNTREATED']['all']\n",
    "    C_coeffs = init_dict['COST']['all']\n",
    "    coeffs = [Y0_coeffs, Y1_coeffs, C_coeffs]\n",
    "\n",
    "    V_sd, U1_sd, U0_sd = init_dict['DIST']['all_sd']\n",
    "    vars_ = [U0_sd**2, U1_sd**2, V_sd**2]\n",
    "    \n",
    "    rho = init_dict['DIST']['all_rho']\n",
    "    \n",
    "    num_covars_out = Y1_coeffs.shape[0]\n",
    "    num_covars_cost = C_coeffs.shape[0]\n",
    "\n",
    "    \n",
    "    # Simulate observables\n",
    "    \n",
    "    means = np.tile(0.0, num_covars_out)\n",
    "    covs = np.identity(num_covars_out)\n",
    "    X = np.random.multivariate_normal(means, covs, num_agents)\n",
    "    \n",
    "    means = np.tile(0.0, num_covars_out)\n",
    "    covs = np.identity(num_covars_out)\n",
    "    Z = np.random.multivariate_normal(means, covs, num_agents)\n",
    "    \n",
    "    Z[:,0], X[:,0] = 1.0, 1.0\n",
    "      \n",
    "    # Simulate unobservables \n",
    "    # Read information about the distribution and the specific means from the init dic\n",
    "    \n",
    "    dist= init_dict['DIST']['type']\n",
    "    means= init_dict['DIST']['all_mean']\n",
    "    cov_ = np.multiply(init_dict['DIST']['all_sd'][1:],rho) * V_sd\n",
    "\n",
    "    \n",
    "    U = _simulate_unobservables(dist, cov_, vars_, num_agents, means)\n",
    "    \n",
    "    # Simulate endogeneous variables\n",
    "    \n",
    "    Y, D, Y_1, Y_0 = _simulate_outcomes([X, Z], U, coeffs)\n",
    "     \n",
    "    # Write output file\n",
    "    _write_output([Y, D, Y_1, Y_0], [X, Z], source)           \n",
    "\n",
    "    return Y, Y_1, Y_0, D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = import_process('init.ini')\n",
    "\n",
    "Y, Y1, Y0, D = simulation(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
