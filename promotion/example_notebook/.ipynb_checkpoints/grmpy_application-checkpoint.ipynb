{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# The *grmpy*  package \n",
    "This notebook demonstrates the current capabilities of the *grmpy* package. *grmpy* is an open source package for the programming language python that enables researchers to simulate datasets andestimate parameters using already existing data within the structure of the generalized Roy model. Currently the package serves as a teaching tool for a course on the econometrics of policy evaluation at the University of Bonn. The corresponding lecture materials can be found on [GitHub](https://github.com/HumanCapitalAnalysis/econometrics).  Morover it is thought of as a promotion for the conceptual framework as well as a showcase for basic software engineering practices.\n",
    "\n",
    "For a more detailed overview on the economic background as well as the installation routine feel free to take a look on the [online documentation](https://grmpy.readthedocs.io/en/develop/).\n",
    "\n",
    "The notebook itself is divided in three parts. Firstly we provide a basic outline on how to use the package and introduce the core features. Next we will show that the results obtained by the package's estimation process withstand a critical examination by comparing its performance in the presence of essential heterogeneity with several other estimation approaches like Ordinary Least Squares and Instrumental variables. We conclude by conducting a replication of results from   \n",
    "\n",
    "Carneiro, Pedro, James J. Heckman, and Edward J. Vytlacil. [Estimating Marginal Returns to Education.](https://pubs.aeaweb.org/doi/pdfplus/10.1257/aer.101.6.2754)\n",
    "American Economic Review, 101 (6):2754-81, 2011.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before they package makes use of the normal-linear-in-parameters version generalized Roy model. In addition we assume that the unobservable terms $\\{U_1, U_0, V\\}$ are normal distributed according to the covariance matrix $\\Sigma$. The following set of equations characterize the underlying model:\n",
    "\\begin{align*}\n",
    " &\\textbf{Potential Outcomes} & & \\textbf{Choice}  &\\\\\n",
    " & Y_1 = \\beta_1 X + U_{1} &  &D_i = \\mathbf{1}\\{\\Phi(\\gamma Z) > u_D\\} &\\\\\n",
    " & Y_0 = \\beta_0 X + U_{0} &  & \\text{with $u_D = \\Phi(V)$}  &\\\\\n",
    "&&&&\\\\\n",
    "&\\textbf{Distributional Characteristics}&&&\\\\\n",
    "&\\{U_{1}, U_{0}, V\\} \\sim \\mathcal{N}\\left(0, \\Sigma\\right)&&\\Sigma =  \\begin{bmatrix}\n",
    "    \\sigma_1^{2} & \\sigma_{1,0} & \\sigma_{1,V} \\\\\n",
    "    \\sigma_{1,0} & \\sigma_0^{2} & \\sigma_{0,V} \\\\\n",
    "    \\sigma_{1,V} & \\sigma_{0,V} & \\sigma_V^{2} \\\\\n",
    "  \\end{bmatrix}&\\\\\n",
    "&&&&\\\\\n",
    "& \\textbf{Observed Outcome} &&&\\\\\n",
    "& Y = D Y_1 + (1-D) Y_0 &&&\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "\n",
    "Before we can start with the application examples we have to import several libaries we rely on during this presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import grmpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition we will import some custom functions for plotting several figures of interest as well as some data management purposes. The code is provided in the auxiliary.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auxiliary import process_data\n",
    "from auxiliary import plot_est_mte\n",
    "from auxiliary import monte_carlo\n",
    "from auxiliary import effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I - Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part provides some basic information about the general application of the package's core methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The initialization file\n",
    "\n",
    "Currently the package has two core features. The first one is the simulation process. It enables users to simulate data sets along a pre-specified parameterization. The data generating process follows the structure of the previously introduced parametric Roy model framework. Therefore users specify their desired parametrization in an initialization file which allows to alter any aspects of the model according to their preferences. The ability to estimate parameters on already existing data sets is the second core feature. As before the initialization file is the starting point for the estimation process. \n",
    "\n",
    "The initialization file is structured as following:\n",
    "\n",
    "* **Simulation**: The simulation section contains information for the estimation process. For instance users are able to change the number of individuals for which the program runs a simulation through setting the agents option to a specific value.\n",
    "\n",
    "\n",
    "* **Estimation**: Accordingly information reagrding the estimation process are stored in the estimation section. Here, users can set the type of optimizer which should be used for running the process as well as the maximum number of iteration the process is allowed to perform. In addition the flags *dependent* and *indicator* determine which variable of the input data frame is be seen as the dependent variable and the treatment indicator variable respectively.\n",
    "\n",
    "\n",
    "* **Treated, Untreated, Choice**: This sections are essential for both methods. They contain the parameterization which is used for the simulation process. Additionally the second column indicates the variable labels well as for the simulated data set. This column is also essential for the estimation process because it will only include variables that are pre-specified in an specific section for the following optimization.\n",
    "\n",
    "\n",
    "* **Dist**: The Dist section determines the distributional characteristics of the unobservable variables. Therefore the section reports the upper triangle of the covariance matrix of $(U_1, U_0,V)$.\n",
    "\n",
    "\n",
    "* **SCIPY-BFGS/SCIPY-POWELL**: The SCIPY related sections contain options for the relevant optimization algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file files/tutorial.grmpy.ini\n",
    "   SIMULATION\n",
    "\n",
    "        agents                     10000\n",
    "        seed                       2356\n",
    "        source                     data\n",
    "\n",
    "   ESTIMATION\n",
    "\n",
    "        file                       data.grmpy.txt\n",
    "        output_file                output/est.grmpy.info\n",
    "        optimizer                  SCIPY-BFGS\n",
    "        start                      auto\n",
    "        maxiter                    6383\n",
    "        agents                     165 \n",
    "        dependent                  Y\n",
    "        indicator                  D\n",
    "        comparison                 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   TREATED\n",
    "\n",
    "        coeff          const      1.0000\n",
    "        coeff          X2         0.5550\n",
    "\n",
    "   UNTREATED\n",
    "\n",
    "        coeff          const      0.5000\n",
    "        coeff          X2         0.2500\n",
    "\n",
    "   CHOICE\n",
    "\n",
    "        coeff          const      0.3780\n",
    "        coeff          X3        -0.3900\n",
    "\n",
    "   DIST\n",
    "\n",
    "        coeff                    0.1000\n",
    "        coeff                    0.0000\n",
    "        coeff                    0.0000\n",
    "        coeff                    0.1000\n",
    "        coeff                    0.0000\n",
    "        coeff                    1.0000\n",
    "\n",
    "   SCIPY-BFGS\n",
    "\n",
    "        gtol                    0.00001\n",
    "        eps                     1.4901161193847655e-08\n",
    "\n",
    "   SCIPY-POWELL\n",
    "\n",
    "        xtol                     9.147777614048603e-05\n",
    "        ftol                     9.749582129043358e-05\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Simulation Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simulating a dataset we only have to provide the package with the related inititalization file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = grmpy.simulate('files/tutorial.grmpy.ini')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation process generates an info file that provides additional information about the distribution of outcomes and effects respectively. Additionally it containes the criterion function value, information about the corresponding marginal treatment effect as well as the paramterization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load data.grmpy.info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated data set is specififed so that the treatment selection process is not affected by essential heterogeneity. Therefore the conventional effects are nearly identical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effects(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essential Heterogeneity\n",
    "For providing an example on how essential heterogeneity bias the results obtained by naive comparison between treated and untreated individuals, we alter the initialization file. Specifically we will introduce correlation between the unobservable terms. This lead to the situation where individuals select into treatment based on unobservable gains. Therefore the treatment decision $D$ is no longer independent from the outcomes $Y_1$ and $Y_0$.\n",
    "\n",
    "\\begin{align}\n",
    "Y_1,Y_0\\;\\; {\\perp\\!\\!\\!\\!\\!\\!\\diagup\\!\\!\\!\\!\\!\\!\\!\\perp} \\;\\; D\n",
    "\\end{align}\n",
    "\n",
    "Unlike in the absence of essential heterogeneity individuals who select themselves into treatment differ from\n",
    "individuals who do not in respect of their unobservable characteristics. From this follows that\n",
    "\n",
    "\\begin{align}\n",
    "B^{ATE} \\neq B^{TT} \\neq B^{TUT}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file files/tutorial_eh.grmpy.ini\n",
    "   SIMULATION\n",
    "\n",
    "        seed                                      2356\n",
    "        agents                                   10000\n",
    "        source                                 data_eh\n",
    "\n",
    "   ESTIMATION\n",
    "\n",
    "        file                         data_eh.grmpy.txt\n",
    "        start                                     auto\n",
    "        agents                                     165\n",
    "        optimizer                           SCIPY-BFGS\n",
    "        maxiter                                   6383\n",
    "        dependent                                    Y\n",
    "        indicator                                    D\n",
    "        output_file               output/est.grmpy.info\n",
    "        comparison                                   1\n",
    "\n",
    "   TREATED\n",
    "\n",
    "        coeff               const               1.0000\n",
    "        coeff                  X2               0.5550\n",
    "\n",
    "   UNTREATED\n",
    "\n",
    "        coeff               const               0.5000\n",
    "        coeff                  X2               0.2500\n",
    "\n",
    "   CHOICE\n",
    "\n",
    "        coeff               const               0.3780\n",
    "        coeff                  X3              -0.3900\n",
    "\n",
    "   DIST\n",
    "\n",
    "        coeff                                   0.1000\n",
    "        coeff                                   0.0000\n",
    "        coeff                                   0.0524\n",
    "        coeff                                   0.1000\n",
    "        coeff                                  -0.0216\n",
    "        coeff                                   1.0000\n",
    "\n",
    "   SCIPY-BFGS\n",
    "\n",
    "        gtol                                     1e-05\n",
    "        eps                     1.4901161193847655e-08\n",
    "\n",
    "   SCIPY-POWELL\n",
    "\n",
    "        xtol                     9.147777614048603e-05\n",
    "        ftol                     9.749582129043358e-05\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eh = grmpy.simulate('files/tutorial_eh.grmpy.ini')\n",
    "data_eh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load data_eh.grmpy.info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effects(data_eh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Estimation Process\n",
    "\n",
    "grmpy enables users to estimate parameters on data sets. Execute an estimation is simply. Just setup your estimation specifications in the initialization file and provide the estimation process the according file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt = grmpy.fit('files/tutorial_eh.grmpy.ini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimation process returns a detailed overview on the results via an output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load output/est.grmpy.info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition the process is capable of simulating a new data set according to the estimation results. This enables users to verfiy their obtained results easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load comparison.grmpy.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software Engineering Practices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II - Monte Carlo Simulation\n",
    "\n",
    "For illustrating the advantages of grmpys estimation process in the presence of essential heterogeneity we conduct a monte carlo exercise. As before the starting point of the exericise is an initialization file over which we iterate several times during the process. The distributional characteristics are such that the unobservable variables are distributed according to the following covariance matrix\n",
    "\n",
    "\\begin{align}\n",
    "\\Sigma =  \\begin{bmatrix}\n",
    "    0.01 & 0 & \\frac{\\rho_{1,V}}{0.1}  \\\\\n",
    "    0 & 0.01 & 0 \\\\\n",
    "    \\frac{\\rho_{1,V}}{0.1}  & 0 & 1 \\\\\n",
    "  \\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "During each step of the iteration we increase the correlation between $U_1$ and $V$. We will start from a value of $\\rho_1 =0.0$ and end at $\\rho_1 = 0.99$. This increase is equvialent with the observation of incremental reverse selection behavior, because individuals with a low value of $V$ which are most likely to select into treatment have on average a lower value of $U_1$ than individuals that have larger values of $V$. in addition we estimate the average effect of treatment during each step. For this purpose we use the grmpy estimation process, a Ordinary Least squares regression and a Instrumental Variables approach as well as a naive comparison of outputs between treated and untreated individuals.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Initialization file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file files/mc.grmpy.ini\n",
    "\n",
    "   SIMULATION\n",
    "\n",
    "        seed                                    51353\n",
    "        agents                                   10000\n",
    "        source                                      mc\n",
    "\n",
    "   ESTIMATION\n",
    "\n",
    "        file                              mc.grmpy.txt\n",
    "        start                                     auto\n",
    "        agents                                     165\n",
    "        optimizer                           SCIPY-BFGS\n",
    "        maxiter                                   6383\n",
    "        dependent                                 wage\n",
    "        indicator                                state\n",
    "        output_file                 mc_rslt.grmpy.info\n",
    "        comparison                                   0\n",
    "\n",
    "   TREATED\n",
    "\n",
    "        coeff               const               0.9900\n",
    "        coeff                  X2               0.5550\n",
    "        coeff                  X3              -0.5550\n",
    "        coeff                  X4               0.7550\n",
    "        coeff                  X5               0.1550\n",
    "\n",
    "   UNTREATED\n",
    "\n",
    "        coeff               const               0.5000\n",
    "        coeff                  X2               0.2550\n",
    "        coeff                  X3              -0.2550\n",
    "        coeff                  X4               0.1768\n",
    "        coeff                  X5               0.0987\n",
    "\n",
    "   CHOICE\n",
    "\n",
    "        coeff               const               0.2280\n",
    "        coeff                  X6              -0.3900\n",
    "        coeff                  X7               0.5900\n",
    "        coeff                  X8              -0.0900\n",
    "        coeff                  X9              -0.3300\n",
    "\n",
    "   DIST\n",
    "\n",
    "        coeff                                   0.1000\n",
    "        coeff                                   0.0000\n",
    "        coeff                                   0.0000\n",
    "        coeff                                   0.1000\n",
    "        coeff                                   0.0000\n",
    "        coeff                                   1.0000\n",
    "\n",
    "   SCIPY-BFGS\n",
    "\n",
    "        gtol                                     1e-05\n",
    "        eps                     1.4901161193847655e-08\n",
    "\n",
    "   SCIPY-POWELL\n",
    "\n",
    "        xtol                     9.147777614048603e-05\n",
    "        ftol                     9.749582129043358e-05\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grmpy.simulate('files/mc.grmpy.ini')\n",
    "monte_carlo('files/mc.grmpy.ini', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the figure, the OLS estimator and the naive comparison of outcomes between the treated and untreated subpopulation underestimates the effect significantly. The stronger the correlation between the unobservable variables the more or less stronger bias. Moreover the IV estimates become upward biased as soon the impact of essential heterogeneity increases. Conversely to the other estimation approaches the grmpy estimate of the average effect is close to the true value even if the unobservables are almost perfectly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III - Replication Carneiro & Heckman & Vytlacil 2011\n",
    "\n",
    "Since the current version of grmpy is not capable of estimating non-parametric versions of the Roy models, our\n",
    "replication of Carneiro et al. (2011) will focus on reproducing the results for the marginal treatment effect for the parametric selection model. Due to reasons of privacy regarding local variables, we ar not able to merge the data provided by the authors so that they fully coincide with the original data set. Therefore our replication setup makes use of a mock data set. For this purpose we randomly merge the individual specific data with the local characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic = pd.read_stata('data/basicvariables.dta')\n",
    "local = pd.read_stata('data/localvariables.dta') \n",
    "df = pd.concat([basic, local], axis = 1)\n",
    "process_data(df,'data/aer-replication-mock')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we have to create a inititalization file that fully coincides with the setup by Carneiro et. al. Therefore we use the information that the authors provide in their appendix to create the following init file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file files/replication.grmpy.ini\n",
    "   SIMULATION\n",
    "\n",
    "        seed                                         5062\n",
    "        agents                                        991\n",
    "        source                                   8EF73AA0\n",
    "\n",
    "   ESTIMATION\n",
    "\n",
    "        file                                         data/aer-replication-mock.pkl\n",
    "        start                                        auto\n",
    "        agents                                       1000\n",
    "        optimizer                                    SCIPY-BFGS\n",
    "        maxiter                                      80000\n",
    "        dependent                                    wage\n",
    "        indicator                                    state\n",
    "        output_file                                  replication.grmp.info\n",
    "        comparison                                   0\n",
    "\n",
    "\n",
    "   TREATED\n",
    "\n",
    "        coeff                   const                 1.0\n",
    "        coeff                   exp                   0.0794\n",
    "        coeff                   expsq                -0.0035\n",
    "        coeff                   lwage5                0.8319\n",
    "        coeff                   lurate                0.0032\n",
    "        coeff                   cafqt                 0.1222\n",
    "        coeff                   cafqtsq               0.0546\n",
    "        coeff                   mhgc                 -0.0097\n",
    "        coeff                   mhgcsq                0.0014\n",
    "        coeff                   numsibs              -0.0102\n",
    "        coeff                   numsibssq             0.0002\n",
    "        coeff                   urban14               0.0457\n",
    "        coeff                   lavlocwage17          0.8999\n",
    "        coeff                   lavlocwage17sq       -0.0431\n",
    "        coeff                   avurate               0.1459\n",
    "        coeff                   avuratesq            -0.0135\n",
    "        coeff                   d57                   1.0\n",
    "        coeff                   d58                   1.0\n",
    "        coeff                   d59                   1.0\n",
    "        coeff                   d60                   1.0\n",
    "        coeff                   d61                   1.0\n",
    "        coeff                   d62                   1.0\n",
    "        coeff                   d63                   1.0\n",
    "\n",
    "   UNTREATED\n",
    "\n",
    "        coeff                   const                 1.0\n",
    "        coeff                   exp                   0.0540\n",
    "        coeff                   expsq                 0.0004\n",
    "        coeff                   lwage5                0.5766\n",
    "        coeff                   lurate               -0.0037\n",
    "        coeff                   cafqt                 0.0506\n",
    "        coeff                   cafqtsq              -0.0494\n",
    "        coeff                   mhgc                 -0.0186\n",
    "        coeff                   mhgcsq                0.0009\n",
    "        coeff                   numsibs               0.0043\n",
    "        coeff                   numsibssq            -0.0005\n",
    "        coeff                   urban14               0.0077\n",
    "        coeff                   lavlocwage17          12.5816\n",
    "        coeff                   lavlocwage17sq       -0.6056\n",
    "        coeff                   avurate               0.0717\n",
    "        coeff                   avuratesq            -0.0059\n",
    "        coeff                   d57                   1.0\n",
    "        coeff                   d58                   1.0\n",
    "        coeff                   d59                   1.0\n",
    "        coeff                   d60                   1.0\n",
    "        coeff                   d61                   1.0\n",
    "        coeff                   d62                   1.0\n",
    "        coeff                   d63                   1.0\n",
    "\n",
    "   CHOICE\n",
    "\n",
    "        coeff                   const                 1.0\n",
    "        coeff                   cafqt                 3.6671\n",
    "        coeff                   cafqtsq               0.2008\n",
    "        coeff                   mhgc                 -1.8348\n",
    "        coeff                   mhgcsq                0.0096\n",
    "        coeff                   numsibs              -4.2234\n",
    "        coeff                   numsibssq             0.0016\n",
    "        coeff                   urban14               0.1058\n",
    "        coeff                   lavlocwage17        -52.9084\n",
    "        coeff                   lavlocwage17sq        2.5985\n",
    "        coeff                   avurate               0.2693\n",
    "        coeff                   avuratesq            -0.0205\n",
    "        coeff                   d57                   1.0\n",
    "        coeff                   d58                   1.0\n",
    "        coeff                   d59                   1.0\n",
    "        coeff                   d60                   1.0\n",
    "        coeff                   d61                   1.0\n",
    "        coeff                   d62                   1.0\n",
    "        coeff                   d63                   1.0\n",
    "        coeff                   lwage5_17numsibs      0.4107\n",
    "        coeff                   lwage5_17mhgc         0.1846\n",
    "        coeff                   lwage5_17cafqt       -0.3072\n",
    "        coeff                   lwage5_17            -4.0536\n",
    "        coeff                   lurate_17             0.4251\n",
    "        coeff                   lurate_17numsibs     -0.0026\n",
    "        coeff                   lurate_17mhgc        -0.0309\n",
    "        coeff                   lurate_17cafqt       -0.0075\n",
    "        coeff                   tuit4c               -0.0520\n",
    "        coeff                   tuit4cnumsibs        -0.0033\n",
    "        coeff                   tuit4cmhgc            0.0044\n",
    "        coeff                   tuit4ccafqt           0.0065\n",
    "        coeff                   pub4                  0.7519\n",
    "        coeff                   pub4numsibs           0.0104\n",
    "        coeff                   pub4mhgc             -0.0559\n",
    "        coeff                   pub4cafqt             0.1585\n",
    "\n",
    "\n",
    "\n",
    "   DIST\n",
    "\n",
    "        coeff                                   0.1000\n",
    "        coeff                                   0.0000\n",
    "        coeff                                   0.0000\n",
    "        coeff                                   0.1000\n",
    "        coeff                                   0.0000\n",
    "        coeff                                   1.0000\n",
    "\n",
    "   SCIPY-BFGS\n",
    "\n",
    "        gtol                    0.00001\n",
    "        eps                     1.4901161193847656e-8\n",
    "\n",
    "   SCIPY-POWELL\n",
    "\n",
    "        xtol                     0.0001\n",
    "        ftol                     0.0001\n",
    "\n",
    "\n",
    "   SCIPY-NELDER-MEAD\n",
    "\n",
    "        fatol                    0.0001\n",
    "        xatol                    0.0001\n",
    "        adaptive                 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then conduct an estimation based on the initialization file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt = grmpy.fit('files/replication.grmpy.ini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we plot $B^{MTE}$ based on our estimation results. As shown in the figure below the results are really close to the original results. The deviation seems to be negligible because of the usage of a mock dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mte = plot_est_mte(rslt, 'files/replication.grmpy.ini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "The package is build on the following main references:\n",
    "\n",
    "James J. Heckman and Edward J. Vytlacil. [Econometric evaluation of social programs, part I: Causal models, structural models and econometric policy evaluation.](https://www.sciencedirect.com/science/article/pii/S1573441207060709) In Handbook of Econometrics, volume 6B, chapter 70, pages 4779–4874. Elsevier Science, 2007.\n",
    "\n",
    "\n",
    "James J. Heckman and Edward J. Vytlacil. [Econometric evaluation of social programs, part II: Using the marginal treatment effect to organize alternative econometric estimators to evaluate social programs, and to forecast their effects in new environments.](https://www.sciencedirect.com/science/article/pii/S1573441207060710) In Handbook of Econometrics, volume 6B, chapter 71, pages 4875–5143. Elsevier Science, 2007.\n",
    "\n",
    "\n",
    "Jaap H. Abbring and James J. Heckman. [Econometric evaluation of social programs, part III: Distributional treatment effects, dynamic treatment effects, dynamic discrete choice, and general equilibrium policy evaluation.](https://www.sciencedirect.com/science/article/pii/S1573441207060722) Handbook of Econometrics, volume 6B, chapter 72, pages 5145-5303. Elsevier Science, 2007.\n",
    "\n",
    "For a detailed overview on the theoretical economic background, more application examples as well as contact informations see the [online documentation](https://grmpy.readthedocs.io/en/latest/index.html). In addition, the most current code is available on [GitHub](https://github.com/OpenSourceEconomics/grmpy).\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:replication]",
   "language": "python",
   "name": "conda-env-replication-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
